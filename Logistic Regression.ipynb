{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:50.754903Z",
     "start_time": "2025-03-09T22:58:50.752495Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Men's Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2ce688b25d32fa8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load data into Pandas dataframes\n",
    "mRegDetail = pd.read_csv('data/men data/MRegularSeasonDetailedResults.csv')\n",
    "mTournCompact = pd.read_csv('data/men data/MNCAATourneyCompactResults.csv')\n",
    "mNames = pd.read_csv('data/men data/MTeamSpellings.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:50.920450Z",
     "start_time": "2025-03-09T22:58:50.779708Z"
    }
   },
   "id": "3cd32e70e72f9f34",
   "execution_count": 406
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore',\n       'WLoc', 'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA',\n       'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA',\n       'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO',\n       'LStl', 'LBlk', 'LPF'], dtype=object)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mRegDetail.columns.values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:50.924602Z",
     "start_time": "2025-03-09T22:58:50.921488Z"
    }
   },
   "id": "80b747df2f35b319",
   "execution_count": 407
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Split regular season detailed results into dataframes focused on outcome for one team\n",
    "mRegWinners = pd.DataFrame()\n",
    "mRegLossers = pd.DataFrame()\n",
    "\n",
    "# Establish new columns for that includes stats for one team\n",
    "columns = ['Season', 'TeamID', 'Score', 'OppScore',\n",
    "       'NumOT', 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA',\n",
    "       'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF', 'OppFGM', 'OppFGA',\n",
    "       'OppFGM3', 'OppFGA3', 'OppFTM', 'OppFTA', 'OppOR', 'OppDR', 'OppAst', 'OppTO',\n",
    "       'OppStl', 'OppBlk', 'OppPF']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:50.939038Z",
     "start_time": "2025-03-09T22:58:50.924602Z"
    }
   },
   "id": "bf43b1c86fc39a42",
   "execution_count": 408
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Split winners from regular season\n",
    "mRegWinners[columns] = mRegDetail[['Season', 'WTeamID', 'WScore', 'LScore',\n",
    "       'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA',\n",
    "       'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA',\n",
    "       'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO',\n",
    "       'LStl', 'LBlk', 'LPF']]\n",
    "\n",
    "# Add wins and losses columns\n",
    "mRegWinners['Wins'] = 1\n",
    "mRegWinners['Losses'] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:50.971217Z",
     "start_time": "2025-03-09T22:58:50.940046Z"
    }
   },
   "id": "1a8acc93dbbae2d7",
   "execution_count": 409
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Split lossers from regular season\n",
    "mRegLossers[columns] = mRegDetail[['Season', 'LTeamID', 'LScore', 'WScore',\n",
    "       'NumOT', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA',\n",
    "       'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF', 'WFGM', 'WFGA',\n",
    "       'WFGM3', 'WFGA3', 'WFTM', 'WFTA','WOR', 'WDR', 'WAst', 'WTO',\n",
    "       'WStl', 'WBlk', 'WPF']]\n",
    "\n",
    "# Add wins and losses columns\n",
    "mRegLossers['Wins'] = 0\n",
    "mRegLossers['Losses'] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:50.988501Z",
     "start_time": "2025-03-09T22:58:50.971217Z"
    }
   },
   "id": "b82d9349edc71d09",
   "execution_count": 410
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Combine all games into one dataframe\n",
    "mAllRegDetail = pd.concat([mRegWinners, mRegLossers])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.003971Z",
     "start_time": "2025-03-09T22:58:50.988501Z"
    }
   },
   "id": "7343b00600410b9b",
   "execution_count": 411
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sum stats for each season for each team for regular season\n",
    "mRegSeasonDetail = mAllRegDetail.groupby(['Season', 'TeamID']).sum(numeric_only=True)\n",
    "mRegSeasonDetail['NumGames'] = mRegSeasonDetail['Wins'] + mRegSeasonDetail['Losses']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.040482Z",
     "start_time": "2025-03-09T22:58:51.003971Z"
    }
   },
   "id": "521360e807d5a23a",
   "execution_count": 412
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Score', 'OppScore', 'NumOT', 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM',\n       'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF', 'OppFGM',\n       'OppFGA', 'OppFGM3', 'OppFGA3', 'OppFTM', 'OppFTA', 'OppOR',\n       'OppDR', 'OppAst', 'OppTO', 'OppStl', 'OppBlk', 'OppPF', 'Wins',\n       'Losses', 'NumGames'], dtype=object)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mRegSeasonDetail.columns.values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.043711Z",
     "start_time": "2025-03-09T22:58:51.040482Z"
    }
   },
   "id": "deab2407330773e",
   "execution_count": 413
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "               Score  OppScore  NumOT  FGM   FGA  FGM3  FGA3  FTM  FTA   OR  \\\nSeason TeamID                                                                 \n2003   1102     1603      1596      0  536  1114   219   583  312  479  117   \n       1103     2127      2110      8  733  1508   147   434  514  698  264   \n       1104     1940      1820      1  673  1601   178   556  416  586  380   \n       1105     1866      1993      4  634  1602   197   540  401  568  351   \n       1106     1781      1785      1  656  1548   171   494  298  461  344   \n...              ...       ...    ...  ...   ...   ...   ...  ...  ...  ...   \n2025   1476     1964      2056      0  676  1561   250   701  362  499  204   \n       1477     1995      2321      1  713  1714   260   828  309  480  246   \n       1478     2091      2356      7  718  1609   221   669  434  605  216   \n       1479     1842      2009      3  635  1507   196   549  376  466  174   \n       1480     2033      2365      0  760  1779   159   536  354  513  245   \n\n               ...  OppOR  OppDR  OppAst  OppTO  OppStl  OppBlk  OppPF  Wins  \\\nSeason TeamID  ...                                                             \n2003   1102    ...    269    564     256    363     152      44    514    12   \n       1103    ...    325    595     418    414     173      77    606    13   \n       1104    ...    305    634     327    388     155      89    539    17   \n       1105    ...    343    686     411    489     244     109    496     7   \n       1106    ...    317    626     330    422     246      89    452    13   \n...            ...    ...    ...     ...    ...     ...     ...    ...   ...   \n2025   1476    ...    258    644     299    289     196     111    457    13   \n       1477    ...    311    728     491    404     286     119    476     5   \n       1478    ...    302    671     464    318     215      84    512     7   \n       1479    ...    233    662     389    351     161      79    472    12   \n       1480    ...    234    754     471    326     206      93    461     5   \n\n               Losses  NumGames  \nSeason TeamID                    \n2003   1102        16        28  \n       1103        14        27  \n       1104        11        28  \n       1105        19        26  \n       1106        15        28  \n...               ...       ...  \n2025   1476        16        29  \n       1477        26        31  \n       1478        22        29  \n       1479        16        28  \n       1480        25        30  \n\n[7981 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Score</th>\n      <th>OppScore</th>\n      <th>NumOT</th>\n      <th>FGM</th>\n      <th>FGA</th>\n      <th>FGM3</th>\n      <th>FGA3</th>\n      <th>FTM</th>\n      <th>FTA</th>\n      <th>OR</th>\n      <th>...</th>\n      <th>OppOR</th>\n      <th>OppDR</th>\n      <th>OppAst</th>\n      <th>OppTO</th>\n      <th>OppStl</th>\n      <th>OppBlk</th>\n      <th>OppPF</th>\n      <th>Wins</th>\n      <th>Losses</th>\n      <th>NumGames</th>\n    </tr>\n    <tr>\n      <th>Season</th>\n      <th>TeamID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">2003</th>\n      <th>1102</th>\n      <td>1603</td>\n      <td>1596</td>\n      <td>0</td>\n      <td>536</td>\n      <td>1114</td>\n      <td>219</td>\n      <td>583</td>\n      <td>312</td>\n      <td>479</td>\n      <td>117</td>\n      <td>...</td>\n      <td>269</td>\n      <td>564</td>\n      <td>256</td>\n      <td>363</td>\n      <td>152</td>\n      <td>44</td>\n      <td>514</td>\n      <td>12</td>\n      <td>16</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>1103</th>\n      <td>2127</td>\n      <td>2110</td>\n      <td>8</td>\n      <td>733</td>\n      <td>1508</td>\n      <td>147</td>\n      <td>434</td>\n      <td>514</td>\n      <td>698</td>\n      <td>264</td>\n      <td>...</td>\n      <td>325</td>\n      <td>595</td>\n      <td>418</td>\n      <td>414</td>\n      <td>173</td>\n      <td>77</td>\n      <td>606</td>\n      <td>13</td>\n      <td>14</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>1104</th>\n      <td>1940</td>\n      <td>1820</td>\n      <td>1</td>\n      <td>673</td>\n      <td>1601</td>\n      <td>178</td>\n      <td>556</td>\n      <td>416</td>\n      <td>586</td>\n      <td>380</td>\n      <td>...</td>\n      <td>305</td>\n      <td>634</td>\n      <td>327</td>\n      <td>388</td>\n      <td>155</td>\n      <td>89</td>\n      <td>539</td>\n      <td>17</td>\n      <td>11</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>1105</th>\n      <td>1866</td>\n      <td>1993</td>\n      <td>4</td>\n      <td>634</td>\n      <td>1602</td>\n      <td>197</td>\n      <td>540</td>\n      <td>401</td>\n      <td>568</td>\n      <td>351</td>\n      <td>...</td>\n      <td>343</td>\n      <td>686</td>\n      <td>411</td>\n      <td>489</td>\n      <td>244</td>\n      <td>109</td>\n      <td>496</td>\n      <td>7</td>\n      <td>19</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>1106</th>\n      <td>1781</td>\n      <td>1785</td>\n      <td>1</td>\n      <td>656</td>\n      <td>1548</td>\n      <td>171</td>\n      <td>494</td>\n      <td>298</td>\n      <td>461</td>\n      <td>344</td>\n      <td>...</td>\n      <td>317</td>\n      <td>626</td>\n      <td>330</td>\n      <td>422</td>\n      <td>246</td>\n      <td>89</td>\n      <td>452</td>\n      <td>13</td>\n      <td>15</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">2025</th>\n      <th>1476</th>\n      <td>1964</td>\n      <td>2056</td>\n      <td>0</td>\n      <td>676</td>\n      <td>1561</td>\n      <td>250</td>\n      <td>701</td>\n      <td>362</td>\n      <td>499</td>\n      <td>204</td>\n      <td>...</td>\n      <td>258</td>\n      <td>644</td>\n      <td>299</td>\n      <td>289</td>\n      <td>196</td>\n      <td>111</td>\n      <td>457</td>\n      <td>13</td>\n      <td>16</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>1477</th>\n      <td>1995</td>\n      <td>2321</td>\n      <td>1</td>\n      <td>713</td>\n      <td>1714</td>\n      <td>260</td>\n      <td>828</td>\n      <td>309</td>\n      <td>480</td>\n      <td>246</td>\n      <td>...</td>\n      <td>311</td>\n      <td>728</td>\n      <td>491</td>\n      <td>404</td>\n      <td>286</td>\n      <td>119</td>\n      <td>476</td>\n      <td>5</td>\n      <td>26</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>1478</th>\n      <td>2091</td>\n      <td>2356</td>\n      <td>7</td>\n      <td>718</td>\n      <td>1609</td>\n      <td>221</td>\n      <td>669</td>\n      <td>434</td>\n      <td>605</td>\n      <td>216</td>\n      <td>...</td>\n      <td>302</td>\n      <td>671</td>\n      <td>464</td>\n      <td>318</td>\n      <td>215</td>\n      <td>84</td>\n      <td>512</td>\n      <td>7</td>\n      <td>22</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>1479</th>\n      <td>1842</td>\n      <td>2009</td>\n      <td>3</td>\n      <td>635</td>\n      <td>1507</td>\n      <td>196</td>\n      <td>549</td>\n      <td>376</td>\n      <td>466</td>\n      <td>174</td>\n      <td>...</td>\n      <td>233</td>\n      <td>662</td>\n      <td>389</td>\n      <td>351</td>\n      <td>161</td>\n      <td>79</td>\n      <td>472</td>\n      <td>12</td>\n      <td>16</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>1480</th>\n      <td>2033</td>\n      <td>2365</td>\n      <td>0</td>\n      <td>760</td>\n      <td>1779</td>\n      <td>159</td>\n      <td>536</td>\n      <td>354</td>\n      <td>513</td>\n      <td>245</td>\n      <td>...</td>\n      <td>234</td>\n      <td>754</td>\n      <td>471</td>\n      <td>326</td>\n      <td>206</td>\n      <td>93</td>\n      <td>461</td>\n      <td>5</td>\n      <td>25</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n<p>7981 rows × 32 columns</p>\n</div>"
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mRegSeasonDetail"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.061310Z",
     "start_time": "2025-03-09T22:58:51.043711Z"
    }
   },
   "id": "99abac55d28e4b2a",
   "execution_count": 414
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             Score     OppScore        NumOT          FGM          FGA  \\\ncount  7981.000000  7981.000000  7981.000000  7981.000000  7981.000000   \nmean   2074.908407  2074.908407     2.038592   730.481894  1670.609698   \nstd     283.860997   229.252643     1.767080   101.760242   193.137376   \nmin     292.000000   339.000000     0.000000    99.000000   229.000000   \n25%    1896.000000  1947.000000     1.000000   666.000000  1561.000000   \n50%    2081.000000  2086.000000     2.000000   731.000000  1681.000000   \n75%    2263.000000  2223.000000     3.000000   796.000000  1796.000000   \nmax    3016.000000  2874.000000    12.000000  1113.000000  2282.000000   \n\n              FGM3         FGA3          FTM          FTA           OR  ...  \\\ncount  7981.000000  7981.000000  7981.000000  7981.000000  7981.000000  ...   \nmean    201.372886   586.539782   412.571733   589.485904   308.813557  ...   \nstd      46.954447   120.412234    78.573769   107.677541    70.248796  ...   \nmin      36.000000   104.000000    58.000000    85.000000    25.000000  ...   \n25%     168.000000   502.000000   360.000000   520.000000   263.000000  ...   \n50%     198.000000   580.000000   411.000000   589.000000   311.000000  ...   \n75%     232.000000   666.000000   464.000000   658.000000   356.000000  ...   \nmax     389.000000  1209.000000   709.000000  1020.000000   555.000000  ...   \n\n             OppOR        OppDR       OppAst        OppTO       OppStl  \\\ncount  7981.000000  7981.000000  7981.000000  7981.000000  7981.000000   \nmean    308.813557   701.262123   387.635509   392.439669   192.658564   \nstd      58.974359    85.703983    57.324465    67.874634    31.737869   \nmin      37.000000   111.000000    80.000000    37.000000    31.000000   \n25%     271.000000   650.000000   352.000000   349.000000   172.000000   \n50%     312.000000   705.000000   388.000000   391.000000   192.000000   \n75%     349.000000   756.000000   425.000000   435.000000   213.000000   \nmax     523.000000  1040.000000   645.000000   704.000000   334.000000   \n\n            OppBlk        OppPF         Wins       Losses     NumGames  \ncount  7981.000000  7981.000000  7981.000000  7981.000000  7981.000000  \nmean     98.668964   540.972685    14.841373    14.841373    29.682747  \nstd      20.763284    74.427939     6.139575     5.296653     2.806203  \nmin      11.000000    75.000000     0.000000     0.000000     4.000000  \n25%      85.000000   496.000000    10.000000    11.000000    28.000000  \n50%      98.000000   543.000000    15.000000    15.000000    30.000000  \n75%     111.000000   590.000000    19.000000    19.000000    32.000000  \nmax     181.000000   795.000000    34.000000    31.000000    36.000000  \n\n[8 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score</th>\n      <th>OppScore</th>\n      <th>NumOT</th>\n      <th>FGM</th>\n      <th>FGA</th>\n      <th>FGM3</th>\n      <th>FGA3</th>\n      <th>FTM</th>\n      <th>FTA</th>\n      <th>OR</th>\n      <th>...</th>\n      <th>OppOR</th>\n      <th>OppDR</th>\n      <th>OppAst</th>\n      <th>OppTO</th>\n      <th>OppStl</th>\n      <th>OppBlk</th>\n      <th>OppPF</th>\n      <th>Wins</th>\n      <th>Losses</th>\n      <th>NumGames</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>...</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n      <td>7981.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2074.908407</td>\n      <td>2074.908407</td>\n      <td>2.038592</td>\n      <td>730.481894</td>\n      <td>1670.609698</td>\n      <td>201.372886</td>\n      <td>586.539782</td>\n      <td>412.571733</td>\n      <td>589.485904</td>\n      <td>308.813557</td>\n      <td>...</td>\n      <td>308.813557</td>\n      <td>701.262123</td>\n      <td>387.635509</td>\n      <td>392.439669</td>\n      <td>192.658564</td>\n      <td>98.668964</td>\n      <td>540.972685</td>\n      <td>14.841373</td>\n      <td>14.841373</td>\n      <td>29.682747</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>283.860997</td>\n      <td>229.252643</td>\n      <td>1.767080</td>\n      <td>101.760242</td>\n      <td>193.137376</td>\n      <td>46.954447</td>\n      <td>120.412234</td>\n      <td>78.573769</td>\n      <td>107.677541</td>\n      <td>70.248796</td>\n      <td>...</td>\n      <td>58.974359</td>\n      <td>85.703983</td>\n      <td>57.324465</td>\n      <td>67.874634</td>\n      <td>31.737869</td>\n      <td>20.763284</td>\n      <td>74.427939</td>\n      <td>6.139575</td>\n      <td>5.296653</td>\n      <td>2.806203</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>292.000000</td>\n      <td>339.000000</td>\n      <td>0.000000</td>\n      <td>99.000000</td>\n      <td>229.000000</td>\n      <td>36.000000</td>\n      <td>104.000000</td>\n      <td>58.000000</td>\n      <td>85.000000</td>\n      <td>25.000000</td>\n      <td>...</td>\n      <td>37.000000</td>\n      <td>111.000000</td>\n      <td>80.000000</td>\n      <td>37.000000</td>\n      <td>31.000000</td>\n      <td>11.000000</td>\n      <td>75.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1896.000000</td>\n      <td>1947.000000</td>\n      <td>1.000000</td>\n      <td>666.000000</td>\n      <td>1561.000000</td>\n      <td>168.000000</td>\n      <td>502.000000</td>\n      <td>360.000000</td>\n      <td>520.000000</td>\n      <td>263.000000</td>\n      <td>...</td>\n      <td>271.000000</td>\n      <td>650.000000</td>\n      <td>352.000000</td>\n      <td>349.000000</td>\n      <td>172.000000</td>\n      <td>85.000000</td>\n      <td>496.000000</td>\n      <td>10.000000</td>\n      <td>11.000000</td>\n      <td>28.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2081.000000</td>\n      <td>2086.000000</td>\n      <td>2.000000</td>\n      <td>731.000000</td>\n      <td>1681.000000</td>\n      <td>198.000000</td>\n      <td>580.000000</td>\n      <td>411.000000</td>\n      <td>589.000000</td>\n      <td>311.000000</td>\n      <td>...</td>\n      <td>312.000000</td>\n      <td>705.000000</td>\n      <td>388.000000</td>\n      <td>391.000000</td>\n      <td>192.000000</td>\n      <td>98.000000</td>\n      <td>543.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2263.000000</td>\n      <td>2223.000000</td>\n      <td>3.000000</td>\n      <td>796.000000</td>\n      <td>1796.000000</td>\n      <td>232.000000</td>\n      <td>666.000000</td>\n      <td>464.000000</td>\n      <td>658.000000</td>\n      <td>356.000000</td>\n      <td>...</td>\n      <td>349.000000</td>\n      <td>756.000000</td>\n      <td>425.000000</td>\n      <td>435.000000</td>\n      <td>213.000000</td>\n      <td>111.000000</td>\n      <td>590.000000</td>\n      <td>19.000000</td>\n      <td>19.000000</td>\n      <td>32.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3016.000000</td>\n      <td>2874.000000</td>\n      <td>12.000000</td>\n      <td>1113.000000</td>\n      <td>2282.000000</td>\n      <td>389.000000</td>\n      <td>1209.000000</td>\n      <td>709.000000</td>\n      <td>1020.000000</td>\n      <td>555.000000</td>\n      <td>...</td>\n      <td>523.000000</td>\n      <td>1040.000000</td>\n      <td>645.000000</td>\n      <td>704.000000</td>\n      <td>334.000000</td>\n      <td>181.000000</td>\n      <td>795.000000</td>\n      <td>34.000000</td>\n      <td>31.000000</td>\n      <td>36.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 32 columns</p>\n</div>"
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mRegSeasonDetail.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.094965Z",
     "start_time": "2025-03-09T22:58:51.062348Z"
    }
   },
   "id": "bfaa8b31310b144f",
   "execution_count": 415
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Replace 0s in Losses with a small number to avoid dividing by 0\n",
    "mRegSeasonDetail['Losses'] = mRegSeasonDetail['Losses'].replace(0, 1e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.097980Z",
     "start_time": "2025-03-09T22:58:51.094965Z"
    }
   },
   "id": "58a1b2da30413577",
   "execution_count": 416
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create ___ per game stat for each boxscore stat\n",
    "mRegSeasonFeatures = pd.DataFrame()\n",
    "\n",
    "stats = ['Score', 'OppScore', 'NumOT', 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA',\n",
    "       'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF', 'OppFGM', 'OppFGA',\n",
    "       'OppFGM3', 'OppFGA3', 'OppFTM', 'OppFTA', 'OppOR', 'OppDR', 'OppAst', 'OppTO',\n",
    "       'OppStl', 'OppBlk', 'OppPF']\n",
    "\n",
    "for col in stats:\n",
    "    mRegSeasonFeatures[col + '_PerGame'] = mRegSeasonDetail[col] / mRegSeasonDetail['NumGames']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.114675Z",
     "start_time": "2025-03-09T22:58:51.097980Z"
    }
   },
   "id": "4fdbf5f36ac02eb1",
   "execution_count": 417
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create additional features\n",
    "mRegSeasonFeatures['PointRatio'] = mRegSeasonDetail['Score'] / mRegSeasonDetail['OppScore'] # Points ratio\n",
    "mRegSeasonFeatures['W/L'] = mRegSeasonDetail['Wins'] / mRegSeasonDetail['Losses'] # Win/Loss ratio\n",
    "mRegSeasonFeatures['MOV'] = (mRegSeasonDetail['Score'] - mRegSeasonDetail['OppScore']) / mRegSeasonDetail['NumGames'] # Margin of victory\n",
    "mRegSeasonFeatures['TORatio'] = mRegSeasonFeatures['TO_PerGame'] / mRegSeasonFeatures['OppTO_PerGame'] # Turnover ratio\n",
    "mRegSeasonFeatures['FGM%'] = mRegSeasonDetail['FGM'] / mRegSeasonDetail['FGA'] # Scoring efficiency \n",
    "mRegSeasonFeatures['FG3%M'] = mRegSeasonDetail['FGM3'] / mRegSeasonDetail['FGA3'] # 3-Point efficiency\n",
    "mRegSeasonFeatures['FGA3%'] = mRegSeasonDetail['FGA3'] / mRegSeasonDetail['FGA'] # 3-Point attempt rate\n",
    "mRegSeasonFeatures['FTM%'] = mRegSeasonDetail['FTM'] / mRegSeasonDetail['FTA'] # Free throw makes %\n",
    "mRegSeasonFeatures['FTA%'] = mRegSeasonDetail['FTA'] / mRegSeasonDetail['FGA'] # Free throw attempt rate\n",
    "mRegSeasonFeatures['OppFTA%'] = mRegSeasonDetail['OppFTA'] / mRegSeasonDetail['OppFGA'] # Opponent free throw attempt rate\n",
    "mRegSeasonFeatures['OR%'] = mRegSeasonDetail['OR'] / (mRegSeasonDetail['OR'] + mRegSeasonDetail['OppDR']) # Offensive rebound %\n",
    "mRegSeasonFeatures['DR%'] = mRegSeasonDetail['DR'] / (mRegSeasonDetail['DR'] + mRegSeasonDetail['OppOR']) # Defensive rebound %"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.123394Z",
     "start_time": "2025-03-09T22:58:51.114675Z"
    }
   },
   "id": "9bf74cd56f908856",
   "execution_count": 418
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "               Score_PerGame  OppScore_PerGame  NumOT_PerGame  FGM_PerGame  \\\nSeason TeamID                                                                \n2003   1102        57.250000         57.000000       0.000000    19.142857   \n       1103        78.777778         78.148148       0.296296    27.148148   \n       1104        69.285714         65.000000       0.035714    24.035714   \n       1105        71.769231         76.653846       0.153846    24.384615   \n       1106        63.607143         63.750000       0.035714    23.428571   \n...                      ...               ...            ...          ...   \n2025   1476        67.724138         70.896552       0.000000    23.310345   \n       1477        64.354839         74.870968       0.032258    23.000000   \n       1478        72.103448         81.241379       0.241379    24.758621   \n       1479        65.785714         71.750000       0.107143    22.678571   \n       1480        67.766667         78.833333       0.000000    25.333333   \n\n               FGA_PerGame  FGM3_PerGame  FGA3_PerGame  FTM_PerGame  \\\nSeason TeamID                                                         \n2003   1102      39.785714      7.821429     20.821429    11.142857   \n       1103      55.851852      5.444444     16.074074    19.037037   \n       1104      57.178571      6.357143     19.857143    14.857143   \n       1105      61.615385      7.576923     20.769231    15.423077   \n       1106      55.285714      6.107143     17.642857    10.642857   \n...                    ...           ...           ...          ...   \n2025   1476      53.827586      8.620690     24.172414    12.482759   \n       1477      55.290323      8.387097     26.709677     9.967742   \n       1478      55.482759      7.620690     23.068966    14.965517   \n       1479      53.821429      7.000000     19.607143    13.428571   \n       1480      59.300000      5.300000     17.866667    11.800000   \n\n               FTA_PerGame  OR_PerGame  ...        MOV   TORatio      FGM%  \\\nSeason TeamID                           ...                                  \n2003   1102      17.107143    4.178571  ...   0.250000  0.881543  0.481149   \n       1103      25.851852    9.777778  ...   0.629630  0.823671  0.486074   \n       1104      20.928571   13.571429  ...   4.285714  0.958763  0.420362   \n       1105      21.846154   13.500000  ...  -4.884615  0.991820  0.395755   \n       1106      16.464286   12.285714  ...  -0.142857  1.130332  0.423773   \n...                    ...         ...  ...        ...       ...       ...   \n2025   1476      17.206897    7.034483  ...  -3.172414  1.124567  0.433056   \n       1477      15.483871    7.935484  ... -10.516129  1.121287  0.415986   \n       1478      20.862069    7.448276  ...  -9.137931  1.185535  0.446240   \n       1479      16.642857    6.214286  ...  -5.964286  0.777778  0.421367   \n       1480      17.100000    8.166667  ... -11.066667  0.969325  0.427206   \n\n                  FG3%M     FGA3%      FTM%      FTA%   OppFTA%       OR%  \\\nSeason TeamID                                                               \n2003   1102    0.375643  0.523339  0.651357  0.429982  0.453704  0.171806   \n       1103    0.338710  0.287798  0.736390  0.462865  0.388564  0.307334   \n       1104    0.320144  0.347283  0.709898  0.366021  0.308880  0.374753   \n       1105    0.364815  0.337079  0.705986  0.354557  0.415525  0.338476   \n       1106    0.346154  0.319121  0.646421  0.297804  0.411371  0.354639   \n...                 ...       ...       ...       ...       ...       ...   \n2025   1476    0.356633  0.449071  0.725451  0.319667  0.330079  0.240566   \n       1477    0.314010  0.483081  0.643750  0.280047  0.364834  0.252567   \n       1478    0.330344  0.415786  0.717355  0.376010  0.371396  0.243517   \n       1479    0.357013  0.364300  0.806867  0.309224  0.382775  0.208134   \n       1480    0.296642  0.301293  0.690058  0.288364  0.362573  0.245245   \n\n                    DR%  \nSeason TeamID            \n2003   1102    0.636486  \n       1103    0.623407  \n       1104    0.687179  \n       1105    0.636653  \n       1106    0.678173  \n...                 ...  \n2025   1476    0.715859  \n       1477    0.654444  \n       1478    0.676313  \n       1479    0.686406  \n       1480    0.730725  \n\n[7981 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Score_PerGame</th>\n      <th>OppScore_PerGame</th>\n      <th>NumOT_PerGame</th>\n      <th>FGM_PerGame</th>\n      <th>FGA_PerGame</th>\n      <th>FGM3_PerGame</th>\n      <th>FGA3_PerGame</th>\n      <th>FTM_PerGame</th>\n      <th>FTA_PerGame</th>\n      <th>OR_PerGame</th>\n      <th>...</th>\n      <th>MOV</th>\n      <th>TORatio</th>\n      <th>FGM%</th>\n      <th>FG3%M</th>\n      <th>FGA3%</th>\n      <th>FTM%</th>\n      <th>FTA%</th>\n      <th>OppFTA%</th>\n      <th>OR%</th>\n      <th>DR%</th>\n    </tr>\n    <tr>\n      <th>Season</th>\n      <th>TeamID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">2003</th>\n      <th>1102</th>\n      <td>57.250000</td>\n      <td>57.000000</td>\n      <td>0.000000</td>\n      <td>19.142857</td>\n      <td>39.785714</td>\n      <td>7.821429</td>\n      <td>20.821429</td>\n      <td>11.142857</td>\n      <td>17.107143</td>\n      <td>4.178571</td>\n      <td>...</td>\n      <td>0.250000</td>\n      <td>0.881543</td>\n      <td>0.481149</td>\n      <td>0.375643</td>\n      <td>0.523339</td>\n      <td>0.651357</td>\n      <td>0.429982</td>\n      <td>0.453704</td>\n      <td>0.171806</td>\n      <td>0.636486</td>\n    </tr>\n    <tr>\n      <th>1103</th>\n      <td>78.777778</td>\n      <td>78.148148</td>\n      <td>0.296296</td>\n      <td>27.148148</td>\n      <td>55.851852</td>\n      <td>5.444444</td>\n      <td>16.074074</td>\n      <td>19.037037</td>\n      <td>25.851852</td>\n      <td>9.777778</td>\n      <td>...</td>\n      <td>0.629630</td>\n      <td>0.823671</td>\n      <td>0.486074</td>\n      <td>0.338710</td>\n      <td>0.287798</td>\n      <td>0.736390</td>\n      <td>0.462865</td>\n      <td>0.388564</td>\n      <td>0.307334</td>\n      <td>0.623407</td>\n    </tr>\n    <tr>\n      <th>1104</th>\n      <td>69.285714</td>\n      <td>65.000000</td>\n      <td>0.035714</td>\n      <td>24.035714</td>\n      <td>57.178571</td>\n      <td>6.357143</td>\n      <td>19.857143</td>\n      <td>14.857143</td>\n      <td>20.928571</td>\n      <td>13.571429</td>\n      <td>...</td>\n      <td>4.285714</td>\n      <td>0.958763</td>\n      <td>0.420362</td>\n      <td>0.320144</td>\n      <td>0.347283</td>\n      <td>0.709898</td>\n      <td>0.366021</td>\n      <td>0.308880</td>\n      <td>0.374753</td>\n      <td>0.687179</td>\n    </tr>\n    <tr>\n      <th>1105</th>\n      <td>71.769231</td>\n      <td>76.653846</td>\n      <td>0.153846</td>\n      <td>24.384615</td>\n      <td>61.615385</td>\n      <td>7.576923</td>\n      <td>20.769231</td>\n      <td>15.423077</td>\n      <td>21.846154</td>\n      <td>13.500000</td>\n      <td>...</td>\n      <td>-4.884615</td>\n      <td>0.991820</td>\n      <td>0.395755</td>\n      <td>0.364815</td>\n      <td>0.337079</td>\n      <td>0.705986</td>\n      <td>0.354557</td>\n      <td>0.415525</td>\n      <td>0.338476</td>\n      <td>0.636653</td>\n    </tr>\n    <tr>\n      <th>1106</th>\n      <td>63.607143</td>\n      <td>63.750000</td>\n      <td>0.035714</td>\n      <td>23.428571</td>\n      <td>55.285714</td>\n      <td>6.107143</td>\n      <td>17.642857</td>\n      <td>10.642857</td>\n      <td>16.464286</td>\n      <td>12.285714</td>\n      <td>...</td>\n      <td>-0.142857</td>\n      <td>1.130332</td>\n      <td>0.423773</td>\n      <td>0.346154</td>\n      <td>0.319121</td>\n      <td>0.646421</td>\n      <td>0.297804</td>\n      <td>0.411371</td>\n      <td>0.354639</td>\n      <td>0.678173</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">2025</th>\n      <th>1476</th>\n      <td>67.724138</td>\n      <td>70.896552</td>\n      <td>0.000000</td>\n      <td>23.310345</td>\n      <td>53.827586</td>\n      <td>8.620690</td>\n      <td>24.172414</td>\n      <td>12.482759</td>\n      <td>17.206897</td>\n      <td>7.034483</td>\n      <td>...</td>\n      <td>-3.172414</td>\n      <td>1.124567</td>\n      <td>0.433056</td>\n      <td>0.356633</td>\n      <td>0.449071</td>\n      <td>0.725451</td>\n      <td>0.319667</td>\n      <td>0.330079</td>\n      <td>0.240566</td>\n      <td>0.715859</td>\n    </tr>\n    <tr>\n      <th>1477</th>\n      <td>64.354839</td>\n      <td>74.870968</td>\n      <td>0.032258</td>\n      <td>23.000000</td>\n      <td>55.290323</td>\n      <td>8.387097</td>\n      <td>26.709677</td>\n      <td>9.967742</td>\n      <td>15.483871</td>\n      <td>7.935484</td>\n      <td>...</td>\n      <td>-10.516129</td>\n      <td>1.121287</td>\n      <td>0.415986</td>\n      <td>0.314010</td>\n      <td>0.483081</td>\n      <td>0.643750</td>\n      <td>0.280047</td>\n      <td>0.364834</td>\n      <td>0.252567</td>\n      <td>0.654444</td>\n    </tr>\n    <tr>\n      <th>1478</th>\n      <td>72.103448</td>\n      <td>81.241379</td>\n      <td>0.241379</td>\n      <td>24.758621</td>\n      <td>55.482759</td>\n      <td>7.620690</td>\n      <td>23.068966</td>\n      <td>14.965517</td>\n      <td>20.862069</td>\n      <td>7.448276</td>\n      <td>...</td>\n      <td>-9.137931</td>\n      <td>1.185535</td>\n      <td>0.446240</td>\n      <td>0.330344</td>\n      <td>0.415786</td>\n      <td>0.717355</td>\n      <td>0.376010</td>\n      <td>0.371396</td>\n      <td>0.243517</td>\n      <td>0.676313</td>\n    </tr>\n    <tr>\n      <th>1479</th>\n      <td>65.785714</td>\n      <td>71.750000</td>\n      <td>0.107143</td>\n      <td>22.678571</td>\n      <td>53.821429</td>\n      <td>7.000000</td>\n      <td>19.607143</td>\n      <td>13.428571</td>\n      <td>16.642857</td>\n      <td>6.214286</td>\n      <td>...</td>\n      <td>-5.964286</td>\n      <td>0.777778</td>\n      <td>0.421367</td>\n      <td>0.357013</td>\n      <td>0.364300</td>\n      <td>0.806867</td>\n      <td>0.309224</td>\n      <td>0.382775</td>\n      <td>0.208134</td>\n      <td>0.686406</td>\n    </tr>\n    <tr>\n      <th>1480</th>\n      <td>67.766667</td>\n      <td>78.833333</td>\n      <td>0.000000</td>\n      <td>25.333333</td>\n      <td>59.300000</td>\n      <td>5.300000</td>\n      <td>17.866667</td>\n      <td>11.800000</td>\n      <td>17.100000</td>\n      <td>8.166667</td>\n      <td>...</td>\n      <td>-11.066667</td>\n      <td>0.969325</td>\n      <td>0.427206</td>\n      <td>0.296642</td>\n      <td>0.301293</td>\n      <td>0.690058</td>\n      <td>0.288364</td>\n      <td>0.362573</td>\n      <td>0.245245</td>\n      <td>0.730725</td>\n    </tr>\n  </tbody>\n</table>\n<p>7981 rows × 41 columns</p>\n</div>"
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mRegSeasonFeatures"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.142161Z",
     "start_time": "2025-03-09T22:58:51.123394Z"
    }
   },
   "id": "7ab0f9388383e46a",
   "execution_count": 419
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT\n0       1985     136     1116      63     1234      54    N      0\n1       1985     136     1120      59     1345      58    N      0\n2       1985     136     1207      68     1250      43    N      0\n3       1985     136     1229      58     1425      55    N      0\n4       1985     136     1242      49     1325      38    N      0\n...      ...     ...      ...     ...      ...     ...  ...    ...\n2513    2024     146     1301      76     1181      64    N      0\n2514    2024     146     1345      72     1397      66    N      0\n2515    2024     152     1163      86     1104      72    N      0\n2516    2024     152     1345      63     1301      50    N      0\n2517    2024     154     1163      75     1345      60    N      0\n\n[2518 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Season</th>\n      <th>DayNum</th>\n      <th>WTeamID</th>\n      <th>WScore</th>\n      <th>LTeamID</th>\n      <th>LScore</th>\n      <th>WLoc</th>\n      <th>NumOT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1985</td>\n      <td>136</td>\n      <td>1116</td>\n      <td>63</td>\n      <td>1234</td>\n      <td>54</td>\n      <td>N</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1985</td>\n      <td>136</td>\n      <td>1120</td>\n      <td>59</td>\n      <td>1345</td>\n      <td>58</td>\n      <td>N</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1985</td>\n      <td>136</td>\n      <td>1207</td>\n      <td>68</td>\n      <td>1250</td>\n      <td>43</td>\n      <td>N</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1985</td>\n      <td>136</td>\n      <td>1229</td>\n      <td>58</td>\n      <td>1425</td>\n      <td>55</td>\n      <td>N</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1985</td>\n      <td>136</td>\n      <td>1242</td>\n      <td>49</td>\n      <td>1325</td>\n      <td>38</td>\n      <td>N</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2513</th>\n      <td>2024</td>\n      <td>146</td>\n      <td>1301</td>\n      <td>76</td>\n      <td>1181</td>\n      <td>64</td>\n      <td>N</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2514</th>\n      <td>2024</td>\n      <td>146</td>\n      <td>1345</td>\n      <td>72</td>\n      <td>1397</td>\n      <td>66</td>\n      <td>N</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2515</th>\n      <td>2024</td>\n      <td>152</td>\n      <td>1163</td>\n      <td>86</td>\n      <td>1104</td>\n      <td>72</td>\n      <td>N</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2516</th>\n      <td>2024</td>\n      <td>152</td>\n      <td>1345</td>\n      <td>63</td>\n      <td>1301</td>\n      <td>50</td>\n      <td>N</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2517</th>\n      <td>2024</td>\n      <td>154</td>\n      <td>1163</td>\n      <td>75</td>\n      <td>1345</td>\n      <td>60</td>\n      <td>N</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2518 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mTournCompact"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.148389Z",
     "start_time": "2025-03-09T22:58:51.142161Z"
    }
   },
   "id": "4d8063d1e06a234d",
   "execution_count": 420
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Split compact tournament results into individual rows of winners and losers to introduce target feature \"Result\"\n",
    "mWTourney = pd.DataFrame()\n",
    "mWTourney[['Season', 'Team1', 'Team2']] = mTournCompact[['Season', 'WTeamID', 'LTeamID']]\n",
    "mWTourney['Result'] = 1\n",
    "\n",
    "mLTourney = pd.DataFrame()\n",
    "mLTourney[['Season', 'Team1', 'Team2']] = mTournCompact[['Season', 'LTeamID', 'WTeamID']]\n",
    "mLTourney['Result'] = 0\n",
    "\n",
    "# Join individual together and drop games earlier than 03 to match up with regular season data\n",
    "mTourneyInput = pd.concat([mWTourney, mLTourney])\n",
    "mTourneyInput = mTourneyInput[mTourneyInput['Season'] >= 2003].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.166763Z",
     "start_time": "2025-03-09T22:58:51.148389Z"
    }
   },
   "id": "20c7654251f5750",
   "execution_count": 421
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      Season  Team1  Team2  Result\n0       2003   1421   1411       1\n1       2003   1112   1436       1\n2       2003   1113   1272       1\n3       2003   1141   1166       1\n4       2003   1143   1301       1\n...      ...    ...    ...     ...\n2759    2024   1181   1301       0\n2760    2024   1397   1345       0\n2761    2024   1104   1163       0\n2762    2024   1301   1345       0\n2763    2024   1345   1163       0\n\n[2764 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Season</th>\n      <th>Team1</th>\n      <th>Team2</th>\n      <th>Result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2003</td>\n      <td>1421</td>\n      <td>1411</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2003</td>\n      <td>1112</td>\n      <td>1436</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2003</td>\n      <td>1113</td>\n      <td>1272</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2003</td>\n      <td>1141</td>\n      <td>1166</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2003</td>\n      <td>1143</td>\n      <td>1301</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2759</th>\n      <td>2024</td>\n      <td>1181</td>\n      <td>1301</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2760</th>\n      <td>2024</td>\n      <td>1397</td>\n      <td>1345</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2761</th>\n      <td>2024</td>\n      <td>1104</td>\n      <td>1163</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2762</th>\n      <td>2024</td>\n      <td>1301</td>\n      <td>1345</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2763</th>\n      <td>2024</td>\n      <td>1345</td>\n      <td>1163</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2764 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mTourneyInput"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.171970Z",
     "start_time": "2025-03-09T22:58:51.166763Z"
    }
   },
   "id": "c66d09e57dad500b",
   "execution_count": 422
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Merge two team stats from mRegSeasonFeatures\n",
    "mTourneyFinal = mTourneyInput.merge(mRegSeasonFeatures, left_on=['Season', 'Team1'], right_index=True, suffixes=('', '_T1'))\n",
    "mTourneyFinal = mTourneyFinal.merge(mRegSeasonFeatures, left_on=['Season', 'Team2'], right_index=True, suffixes=('_T1', '_T2'))\n",
    "\n",
    "# Drop columns that are not needed\n",
    "mTourneyFinal.drop(columns=['Season', 'Team1', 'Team2'], inplace=True)\n",
    "\n",
    "# Calculate the differences (Team1 - Team2) for the features for inpout to linear regression\n",
    "featureCols = [col for col in mRegSeasonFeatures if col not in ['Season', 'TeamID']]\n",
    "for col in featureCols:\n",
    "       mTourneyFinal[col + '_Diff'] = mTourneyFinal[col + '_T1'] - mTourneyFinal[col + '_T2']\n",
    "       \n",
    "# Drop all _T1 and _T2, keep only _Diff and Result\n",
    "mTourneyFinal = mTourneyFinal[[col + '_Diff' for col in featureCols] + ['Result']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.194656Z",
     "start_time": "2025-03-09T22:58:51.171970Z"
    }
   },
   "id": "9c860d12295d5b03",
   "execution_count": 423
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      Score_PerGame_Diff  OppScore_PerGame_Diff  NumOT_PerGame_Diff  \\\n0              -1.593103               7.614943            0.139080   \n1              17.421182               7.112069            0.002463   \n2               1.448276               3.344828            0.034483   \n3               0.102403               8.908046           -0.030303   \n4               2.082759               1.758621            0.070115   \n...                  ...                    ...                 ...   \n2759            3.482639              -5.256944           -0.083333   \n2760           -3.925189              -2.276515           -0.090909   \n2761            9.279412              16.650735            0.062500   \n2762           -7.032828               2.542929           -0.007576   \n2763            1.923351               5.739750            0.090909   \n\n      FGM_PerGame_Diff  FGA_PerGame_Diff  FGM3_PerGame_Diff  \\\n0            -0.354023          1.526437           0.549425   \n1             5.493842          9.852217           1.759852   \n2             0.931034         -3.103448          -3.000000   \n3            -2.076280         -4.764890          -1.142111   \n4             3.011494          5.390805          -1.552874   \n...                ...               ...                ...   \n2759          1.142361         -1.753472           1.288194   \n2760         -1.077652          3.356061           0.385417   \n2761          1.818015          6.102941           2.268382   \n2762         -1.126263          2.578283          -1.277778   \n2763         -0.573084         -0.253119          -0.460784   \n\n      FGA3_PerGame_Diff  FTM_PerGame_Diff  FTA_PerGame_Diff  OR_PerGame_Diff  \\\n0             -0.500000         -1.434483         -7.135632        -0.890805   \n1              4.588670          4.673645          5.448276         2.213054   \n2             -7.482759          2.586207          3.310345        -0.379310   \n3             -2.553814          5.397074          5.142111        -0.292581   \n4             -5.465517         -2.387356         -0.949425         1.508046   \n...                 ...               ...               ...              ...   \n2759           1.736111         -0.090278          0.194444        -0.055556   \n2760           5.075758         -2.155303         -3.812500        -0.280303   \n2761           6.310662          3.375000          3.283088         0.943015   \n2762          -0.035354         -3.502525         -5.194444        -1.974747   \n2763          -3.546346          3.530303          5.470588         0.942068   \n\n      ...  TORatio_Diff  FGM%_Diff  FG3%M_Diff  FGA3%_Diff  FTM%_Diff  \\\n0     ...      0.200650  -0.018262    0.039433   -0.017801   0.142815   \n1     ...     -0.205109   0.016969    0.009777    0.028274   0.043580   \n2     ...     -0.013110   0.040251   -0.030989   -0.113271   0.016122   \n3     ...      0.351889   0.005763   -0.008284   -0.016226   0.072864   \n4     ...     -0.021196   0.009399    0.022444   -0.131799  -0.084846   \n...   ...           ...        ...         ...         ...        ...   \n2759  ...      0.061522   0.032591    0.031070    0.039218  -0.011645   \n2760  ...     -0.355366  -0.043992   -0.066100    0.063189   0.028050   \n2761  ...      0.143301  -0.018671   -0.001546    0.058938   0.041092   \n2762  ...     -0.354789  -0.039121   -0.061963   -0.015370   0.012308   \n2763  ...      0.249076  -0.007664    0.041141   -0.058960  -0.021258   \n\n      FTA%_Diff  OppFTA%_Diff  OR%_Diff  DR%_Diff  Result  \n0     -0.139292      0.059755 -0.015697 -0.047099       1  \n1      0.030435     -0.012280  0.022337 -0.050163       1  \n2      0.078997      0.010485  0.026172  0.001629       1  \n3      0.129120      0.077414  0.021658 -0.021651       1  \n4     -0.051395     -0.102222  0.015999  0.009181       1  \n...         ...           ...       ...       ...     ...  \n2759   0.012902     -0.043363  0.024170  0.024492       0  \n2760  -0.085009      0.127730 -0.050729 -0.036588       0  \n2761   0.019318      0.071454 -0.018376 -0.046929       0  \n2762  -0.103297      0.089519 -0.098329 -0.031517       0  \n2763   0.095128     -0.094833  0.015935 -0.001183       0  \n\n[2764 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score_PerGame_Diff</th>\n      <th>OppScore_PerGame_Diff</th>\n      <th>NumOT_PerGame_Diff</th>\n      <th>FGM_PerGame_Diff</th>\n      <th>FGA_PerGame_Diff</th>\n      <th>FGM3_PerGame_Diff</th>\n      <th>FGA3_PerGame_Diff</th>\n      <th>FTM_PerGame_Diff</th>\n      <th>FTA_PerGame_Diff</th>\n      <th>OR_PerGame_Diff</th>\n      <th>...</th>\n      <th>TORatio_Diff</th>\n      <th>FGM%_Diff</th>\n      <th>FG3%M_Diff</th>\n      <th>FGA3%_Diff</th>\n      <th>FTM%_Diff</th>\n      <th>FTA%_Diff</th>\n      <th>OppFTA%_Diff</th>\n      <th>OR%_Diff</th>\n      <th>DR%_Diff</th>\n      <th>Result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.593103</td>\n      <td>7.614943</td>\n      <td>0.139080</td>\n      <td>-0.354023</td>\n      <td>1.526437</td>\n      <td>0.549425</td>\n      <td>-0.500000</td>\n      <td>-1.434483</td>\n      <td>-7.135632</td>\n      <td>-0.890805</td>\n      <td>...</td>\n      <td>0.200650</td>\n      <td>-0.018262</td>\n      <td>0.039433</td>\n      <td>-0.017801</td>\n      <td>0.142815</td>\n      <td>-0.139292</td>\n      <td>0.059755</td>\n      <td>-0.015697</td>\n      <td>-0.047099</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17.421182</td>\n      <td>7.112069</td>\n      <td>0.002463</td>\n      <td>5.493842</td>\n      <td>9.852217</td>\n      <td>1.759852</td>\n      <td>4.588670</td>\n      <td>4.673645</td>\n      <td>5.448276</td>\n      <td>2.213054</td>\n      <td>...</td>\n      <td>-0.205109</td>\n      <td>0.016969</td>\n      <td>0.009777</td>\n      <td>0.028274</td>\n      <td>0.043580</td>\n      <td>0.030435</td>\n      <td>-0.012280</td>\n      <td>0.022337</td>\n      <td>-0.050163</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.448276</td>\n      <td>3.344828</td>\n      <td>0.034483</td>\n      <td>0.931034</td>\n      <td>-3.103448</td>\n      <td>-3.000000</td>\n      <td>-7.482759</td>\n      <td>2.586207</td>\n      <td>3.310345</td>\n      <td>-0.379310</td>\n      <td>...</td>\n      <td>-0.013110</td>\n      <td>0.040251</td>\n      <td>-0.030989</td>\n      <td>-0.113271</td>\n      <td>0.016122</td>\n      <td>0.078997</td>\n      <td>0.010485</td>\n      <td>0.026172</td>\n      <td>0.001629</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.102403</td>\n      <td>8.908046</td>\n      <td>-0.030303</td>\n      <td>-2.076280</td>\n      <td>-4.764890</td>\n      <td>-1.142111</td>\n      <td>-2.553814</td>\n      <td>5.397074</td>\n      <td>5.142111</td>\n      <td>-0.292581</td>\n      <td>...</td>\n      <td>0.351889</td>\n      <td>0.005763</td>\n      <td>-0.008284</td>\n      <td>-0.016226</td>\n      <td>0.072864</td>\n      <td>0.129120</td>\n      <td>0.077414</td>\n      <td>0.021658</td>\n      <td>-0.021651</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.082759</td>\n      <td>1.758621</td>\n      <td>0.070115</td>\n      <td>3.011494</td>\n      <td>5.390805</td>\n      <td>-1.552874</td>\n      <td>-5.465517</td>\n      <td>-2.387356</td>\n      <td>-0.949425</td>\n      <td>1.508046</td>\n      <td>...</td>\n      <td>-0.021196</td>\n      <td>0.009399</td>\n      <td>0.022444</td>\n      <td>-0.131799</td>\n      <td>-0.084846</td>\n      <td>-0.051395</td>\n      <td>-0.102222</td>\n      <td>0.015999</td>\n      <td>0.009181</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2759</th>\n      <td>3.482639</td>\n      <td>-5.256944</td>\n      <td>-0.083333</td>\n      <td>1.142361</td>\n      <td>-1.753472</td>\n      <td>1.288194</td>\n      <td>1.736111</td>\n      <td>-0.090278</td>\n      <td>0.194444</td>\n      <td>-0.055556</td>\n      <td>...</td>\n      <td>0.061522</td>\n      <td>0.032591</td>\n      <td>0.031070</td>\n      <td>0.039218</td>\n      <td>-0.011645</td>\n      <td>0.012902</td>\n      <td>-0.043363</td>\n      <td>0.024170</td>\n      <td>0.024492</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2760</th>\n      <td>-3.925189</td>\n      <td>-2.276515</td>\n      <td>-0.090909</td>\n      <td>-1.077652</td>\n      <td>3.356061</td>\n      <td>0.385417</td>\n      <td>5.075758</td>\n      <td>-2.155303</td>\n      <td>-3.812500</td>\n      <td>-0.280303</td>\n      <td>...</td>\n      <td>-0.355366</td>\n      <td>-0.043992</td>\n      <td>-0.066100</td>\n      <td>0.063189</td>\n      <td>0.028050</td>\n      <td>-0.085009</td>\n      <td>0.127730</td>\n      <td>-0.050729</td>\n      <td>-0.036588</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2761</th>\n      <td>9.279412</td>\n      <td>16.650735</td>\n      <td>0.062500</td>\n      <td>1.818015</td>\n      <td>6.102941</td>\n      <td>2.268382</td>\n      <td>6.310662</td>\n      <td>3.375000</td>\n      <td>3.283088</td>\n      <td>0.943015</td>\n      <td>...</td>\n      <td>0.143301</td>\n      <td>-0.018671</td>\n      <td>-0.001546</td>\n      <td>0.058938</td>\n      <td>0.041092</td>\n      <td>0.019318</td>\n      <td>0.071454</td>\n      <td>-0.018376</td>\n      <td>-0.046929</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2762</th>\n      <td>-7.032828</td>\n      <td>2.542929</td>\n      <td>-0.007576</td>\n      <td>-1.126263</td>\n      <td>2.578283</td>\n      <td>-1.277778</td>\n      <td>-0.035354</td>\n      <td>-3.502525</td>\n      <td>-5.194444</td>\n      <td>-1.974747</td>\n      <td>...</td>\n      <td>-0.354789</td>\n      <td>-0.039121</td>\n      <td>-0.061963</td>\n      <td>-0.015370</td>\n      <td>0.012308</td>\n      <td>-0.103297</td>\n      <td>0.089519</td>\n      <td>-0.098329</td>\n      <td>-0.031517</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2763</th>\n      <td>1.923351</td>\n      <td>5.739750</td>\n      <td>0.090909</td>\n      <td>-0.573084</td>\n      <td>-0.253119</td>\n      <td>-0.460784</td>\n      <td>-3.546346</td>\n      <td>3.530303</td>\n      <td>5.470588</td>\n      <td>0.942068</td>\n      <td>...</td>\n      <td>0.249076</td>\n      <td>-0.007664</td>\n      <td>0.041141</td>\n      <td>-0.058960</td>\n      <td>-0.021258</td>\n      <td>0.095128</td>\n      <td>-0.094833</td>\n      <td>0.015935</td>\n      <td>-0.001183</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2764 rows × 42 columns</p>\n</div>"
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mTourneyFinal"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.204941Z",
     "start_time": "2025-03-09T22:58:51.194656Z"
    }
   },
   "id": "86b069947466033e",
   "execution_count": 424
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       Score_PerGame_Diff  OppScore_PerGame_Diff  NumOT_PerGame_Diff  \\\ncount         2764.000000            2764.000000         2764.000000   \nmean             0.000000               0.000000            0.000000   \nstd              7.312093               6.355166            0.072274   \nmin            -22.892857             -25.035714           -0.293169   \n25%             -4.857429              -4.330079           -0.035104   \n50%              0.000000               0.000000            0.000000   \n75%              4.857429               4.330079            0.035104   \nmax             22.892857              25.035714            0.293169   \n\n       FGM_PerGame_Diff  FGA_PerGame_Diff  FGM3_PerGame_Diff  \\\ncount       2764.000000      2.764000e+03        2764.000000   \nmean           0.000000      8.226255e-17           0.000000   \nstd            2.914355      4.695264e+00           1.806670   \nmin           -9.357143     -2.207143e+01          -6.062500   \n25%           -1.987506     -3.081258e+00          -1.211338   \n50%            0.000000      0.000000e+00           0.000000   \n75%            1.987506      3.081258e+00           1.211338   \nmax            9.357143      2.207143e+01           6.062500   \n\n       FGA3_PerGame_Diff  FTM_PerGame_Diff  FTA_PerGame_Diff  OR_PerGame_Diff  \\\ncount       2.764000e+03       2764.000000       2764.000000      2764.000000   \nmean        1.028282e-17          0.000000          0.000000         0.000000   \nstd         4.223095e+00          2.702947          3.648958         2.494943   \nmin        -1.427849e+01        -10.205882        -13.094118        -9.214286   \n25%        -2.766433e+00         -1.836522         -2.405540        -1.675716   \n50%         0.000000e+00          0.000000          0.000000         0.000000   \n75%         2.766433e+00          1.836522          2.405540         1.675716   \nmax         1.427849e+01         10.205882         13.094118         9.214286   \n\n       ...  TORatio_Diff    FGM%_Diff   FG3%M_Diff    FGA3%_Diff    FTM%_Diff  \\\ncount  ...   2764.000000  2764.000000  2764.000000  2.764000e+03  2764.000000   \nmean   ...      0.000000     0.000000     0.000000 -1.606690e-19     0.000000   \nstd    ...      0.195575     0.032604     0.037261  7.191683e-02     0.050658   \nmin    ...     -0.606506    -0.135937    -0.139760 -2.727839e-01    -0.172779   \n25%    ...     -0.136510    -0.021822    -0.023834 -4.953287e-02    -0.034681   \n50%    ...      0.000000     0.000000     0.000000  0.000000e+00     0.000000   \n75%    ...      0.136510     0.021822     0.023834  4.953287e-02     0.034681   \nmax    ...      0.606506     0.135937     0.139760  2.727839e-01     0.172779   \n\n          FTA%_Diff  OppFTA%_Diff     OR%_Diff      DR%_Diff      Result  \ncount  2.764000e+03   2764.000000  2764.000000  2.764000e+03  2764.00000  \nmean   3.213381e-19      0.000000     0.000000 -1.606690e-19     0.50000  \nstd    6.419949e-02      0.079799     0.056490  4.051447e-02     0.50009  \nmin   -2.451213e-01     -0.289826    -0.191864 -1.449883e-01     0.00000  \n25%   -4.227682e-02     -0.055724    -0.037664 -2.744192e-02     0.00000  \n50%    0.000000e+00      0.000000     0.000000  0.000000e+00     0.50000  \n75%    4.227682e-02      0.055724     0.037664  2.744192e-02     1.00000  \nmax    2.451213e-01      0.289826     0.191864  1.449883e-01     1.00000  \n\n[8 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score_PerGame_Diff</th>\n      <th>OppScore_PerGame_Diff</th>\n      <th>NumOT_PerGame_Diff</th>\n      <th>FGM_PerGame_Diff</th>\n      <th>FGA_PerGame_Diff</th>\n      <th>FGM3_PerGame_Diff</th>\n      <th>FGA3_PerGame_Diff</th>\n      <th>FTM_PerGame_Diff</th>\n      <th>FTA_PerGame_Diff</th>\n      <th>OR_PerGame_Diff</th>\n      <th>...</th>\n      <th>TORatio_Diff</th>\n      <th>FGM%_Diff</th>\n      <th>FG3%M_Diff</th>\n      <th>FGA3%_Diff</th>\n      <th>FTM%_Diff</th>\n      <th>FTA%_Diff</th>\n      <th>OppFTA%_Diff</th>\n      <th>OR%_Diff</th>\n      <th>DR%_Diff</th>\n      <th>Result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2764.000000</td>\n      <td>2764.000000</td>\n      <td>2764.000000</td>\n      <td>2764.000000</td>\n      <td>2.764000e+03</td>\n      <td>2764.000000</td>\n      <td>2.764000e+03</td>\n      <td>2764.000000</td>\n      <td>2764.000000</td>\n      <td>2764.000000</td>\n      <td>...</td>\n      <td>2764.000000</td>\n      <td>2764.000000</td>\n      <td>2764.000000</td>\n      <td>2.764000e+03</td>\n      <td>2764.000000</td>\n      <td>2.764000e+03</td>\n      <td>2764.000000</td>\n      <td>2764.000000</td>\n      <td>2.764000e+03</td>\n      <td>2764.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>8.226255e-17</td>\n      <td>0.000000</td>\n      <td>1.028282e-17</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.606690e-19</td>\n      <td>0.000000</td>\n      <td>3.213381e-19</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.606690e-19</td>\n      <td>0.50000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7.312093</td>\n      <td>6.355166</td>\n      <td>0.072274</td>\n      <td>2.914355</td>\n      <td>4.695264e+00</td>\n      <td>1.806670</td>\n      <td>4.223095e+00</td>\n      <td>2.702947</td>\n      <td>3.648958</td>\n      <td>2.494943</td>\n      <td>...</td>\n      <td>0.195575</td>\n      <td>0.032604</td>\n      <td>0.037261</td>\n      <td>7.191683e-02</td>\n      <td>0.050658</td>\n      <td>6.419949e-02</td>\n      <td>0.079799</td>\n      <td>0.056490</td>\n      <td>4.051447e-02</td>\n      <td>0.50009</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-22.892857</td>\n      <td>-25.035714</td>\n      <td>-0.293169</td>\n      <td>-9.357143</td>\n      <td>-2.207143e+01</td>\n      <td>-6.062500</td>\n      <td>-1.427849e+01</td>\n      <td>-10.205882</td>\n      <td>-13.094118</td>\n      <td>-9.214286</td>\n      <td>...</td>\n      <td>-0.606506</td>\n      <td>-0.135937</td>\n      <td>-0.139760</td>\n      <td>-2.727839e-01</td>\n      <td>-0.172779</td>\n      <td>-2.451213e-01</td>\n      <td>-0.289826</td>\n      <td>-0.191864</td>\n      <td>-1.449883e-01</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-4.857429</td>\n      <td>-4.330079</td>\n      <td>-0.035104</td>\n      <td>-1.987506</td>\n      <td>-3.081258e+00</td>\n      <td>-1.211338</td>\n      <td>-2.766433e+00</td>\n      <td>-1.836522</td>\n      <td>-2.405540</td>\n      <td>-1.675716</td>\n      <td>...</td>\n      <td>-0.136510</td>\n      <td>-0.021822</td>\n      <td>-0.023834</td>\n      <td>-4.953287e-02</td>\n      <td>-0.034681</td>\n      <td>-4.227682e-02</td>\n      <td>-0.055724</td>\n      <td>-0.037664</td>\n      <td>-2.744192e-02</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.50000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.857429</td>\n      <td>4.330079</td>\n      <td>0.035104</td>\n      <td>1.987506</td>\n      <td>3.081258e+00</td>\n      <td>1.211338</td>\n      <td>2.766433e+00</td>\n      <td>1.836522</td>\n      <td>2.405540</td>\n      <td>1.675716</td>\n      <td>...</td>\n      <td>0.136510</td>\n      <td>0.021822</td>\n      <td>0.023834</td>\n      <td>4.953287e-02</td>\n      <td>0.034681</td>\n      <td>4.227682e-02</td>\n      <td>0.055724</td>\n      <td>0.037664</td>\n      <td>2.744192e-02</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>22.892857</td>\n      <td>25.035714</td>\n      <td>0.293169</td>\n      <td>9.357143</td>\n      <td>2.207143e+01</td>\n      <td>6.062500</td>\n      <td>1.427849e+01</td>\n      <td>10.205882</td>\n      <td>13.094118</td>\n      <td>9.214286</td>\n      <td>...</td>\n      <td>0.606506</td>\n      <td>0.135937</td>\n      <td>0.139760</td>\n      <td>2.727839e-01</td>\n      <td>0.172779</td>\n      <td>2.451213e-01</td>\n      <td>0.289826</td>\n      <td>0.191864</td>\n      <td>1.449883e-01</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 42 columns</p>\n</div>"
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mTourneyFinal.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.253663Z",
     "start_time": "2025-03-09T22:58:51.204941Z"
    }
   },
   "id": "1fba72711e0ededf",
   "execution_count": 425
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ceaff60c7636270"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Setup input and target\n",
    "X = mTourneyFinal.drop(columns=['Result'])\n",
    "y = mTourneyFinal['Result']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit scaler on training data and transform both train and test sets\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)  # Use transform (not fit_transform) on test set to prevent data leakage\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get model predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Convert to DataFrame\n",
    "DFReport = pd.DataFrame(report).T.drop(['accuracy'])\n",
    "\n",
    "# Plot Precision, Recall, and F1-Score\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.heatmap(DFReport.iloc[:-1, :-1], annot=True, cmap=\"Blues\", fmt=\".2f\")\n",
    "\n",
    "plt.title(\"Classification Report Heatmap\")\n",
    "plt.xlabel(\"Metrics\")\n",
    "plt.ylabel(\"Class\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T22:58:51.384154Z",
     "start_time": "2025-03-09T22:58:51.253663Z"
    }
   },
   "id": "d2937abe436269c0",
   "execution_count": 426
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "890faa44057991c6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'C': 1, 'max_iter': 100, 'solver': 'sag', 'tol': 0.0001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Trever\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "grid = {\n",
    "    'C': [0.001, 0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    'max_iter': [100, 250, 500, 750, 1000],\n",
    "    'tol': [1e-4, 1e-5]\n",
    "}\n",
    "\n",
    "gridLog = LogisticRegression()\n",
    "gridSearch = GridSearchCV(gridLog, grid, cv=5, scoring=['precision', 'recall', 'f1'], refit='f1')\n",
    "gridSearch.fit(X_train, y_train)\n",
    "print(f'Best Params: {gridSearch.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T23:00:03.387666Z",
     "start_time": "2025-03-09T22:58:51.384154Z"
    }
   },
   "id": "9702d925c2868bd8",
   "execution_count": 427
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train with new parameters\n",
    "newModel = LogisticRegression(\n",
    "    C=1,\n",
    "    max_iter=1000,\n",
    "    solver='saga',\n",
    "    tol=0.0001\n",
    ")\n",
    "newModel.fit(X_train, y_train)\n",
    "\n",
    "# Get model predictions\n",
    "y_pred = newModel.predict(X_test)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Convert to DataFrame\n",
    "DFReport = pd.DataFrame(report).T.drop(['accuracy'])\n",
    "\n",
    "# Plot Precision, Recall, and F1-Score\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.heatmap(DFReport.iloc[:-1, :-1], annot=True, cmap=\"Blues\", fmt=\".2f\")\n",
    "\n",
    "plt.title(\"Classification Report Heatmap\")\n",
    "plt.xlabel(\"Metrics\")\n",
    "plt.ylabel(\"Class\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T23:00:12.238579Z",
     "start_time": "2025-03-09T23:00:11.963258Z"
    }
   },
   "id": "44c4706b1e15fa9d",
   "execution_count": 429
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
